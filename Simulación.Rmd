---
title: "Simulaciones"
author: "Ana Xiangning Pereira Ezquerro"
date:  "Versión `r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    number_sections: yes
    latex_engine: lualatex
    fig_caption: yes
    toc: yes
    highlight: tango
    df_print: kable
    citation_package: biblatex
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    number_sections: true
    theme: paper
    highlight: tango
  prettydoc::html_pretty:
    toc: true
    df_print: paged
    number_sections: true
    theme: hpstr
    highlight: github
fontsize: 12pt
geometry: margin=0.7in
classoption: a4paper
documentclass: article
header-includes:
- \usepackage{sfmath}
- \renewcommand*\familydefault{\sfdefault}
- \renewcommand{\baselinestretch}{1.2}
- \setlength{\parskip}{1em}
- \usepackage{xcolor}
- \input{confi.tex}
always_allow_html: yes
bibliography: references.bib
biblio-style: bwl-FU
linkcitations: true
linkcolor: blue
lang: es
---

```{r, echo=F, warning=F, message=F}
# Cargamos las funciones
knitr::opts_chunk$set(fig.align='center', fig.width = 10, 
                      fig.height = 8, message=F, comment='', warning=F)
eval(parse("plot_tools.R", encoding="UTF-8"))
eval(parse("arima_simulation.R", encoding="UTF-8"))
eval(parse("auto_fitting.R", encoding="UTF-8"))
eval(parse("auto_selection.R", encoding="UTF-8"))
eval(parse("forecasting.R", encoding="UTF-8"))

# Librerías de series temporales
library(fpp2)
library(tseries)
library(TSA)
library(seastests)
library(forecast)

# Librerías para los gráficos
library(plotly)
library(forecast)

# Auxiliares
library(prettydoc)
library(stringi)
library(stringr)
library(polynom)
library(parallel)

# Función para mostrar y guardar las gráficas de plotly
display <- function(fig, name, width=800, height=400) {
  
  if (is.null(knitr::opts_knit$get("rmarkdown.pandoc.to"))) {
    return(fig)
  }
  if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "latex") {
    figpath <- paste0('figures/', name, ".pdf")
    save_image(fig, figpath, width=width, height=height)
    return(knitr::include_graphics(figpath))
  }
  if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
    fig <- fig %>% layout(width=840, height=700)
    return(fig)
  }
}

dir.create("figures", showWarnings=F)
```

\vspace{2em}

En este documento se exponen múltiples simulaciones de la selección automática de variables con sus respectivos retardos usando una nueva propuesta. Se mostrarán ejemplos donde la selección automática trabaja sobre un conjunto de variables de las cuales sólo algunas inciden en la variable respuesta y con un retardo concreto (aunque siempre menor o igual a 0). A lo largo de las siguientes secciones se irán complicando escenarios con la finalidad de analizar cómo se comporta la nueva propuesta ante datos simulados e inferir a partir de ellos cómo se comportará en escenarios reales.

**Nota**: Para generar los datos de las simulaciones se usó el código `arima_simulation.R`, el cual permite generar de forma pseudo-aleatoria series temporales a partir de un proceso ARIMA. Este documento no muestra cómo generar las series (para evitar la aleatoriedad de los resultados), sino que, una vez generadas y guardadas, se cargan directamente de memoria.

\newpage

# Simulación de un modelo de regresión dinámica con errores estacionarios

En esta sección veremos cómo se comporta la función de selección automática sobre ejemplos muy básicos donde los errores del modelo son estacionarios:

$$Y_t = \beta_0 + \beta_1 X_{t-r_1}^{(1)} + \beta_2 X_{t-r_2}^{(2)} + \cdots + X_{t-r_p}^{(p)}+ \eta_t, \qquad \eta_t \sim \text{ARMA(p,q)}, \quad r_i \geq 0 \text{ para } i=1,..., p $$


## Modelo donde $r_i=0$ para $i=1,...,p$ {#ejemplo1}

Supongamos un modelo de regresión dinámica de tres variables regresoras donde todos los retardos son igual a cero. En concreto, nuestro modelo tendrá la forma:

$$ Y_t = \beta_0 + \beta_1 X_t^{(1)} + \beta_2 X_t^{(2)} + \beta_3 X_t^{(3)} + \eta_t$$

donde:

-   $\eta_t \sim$ ARMA(2,1), por tanto, las innovaciones son estacionarias.
-   $X_t^{(1)} \sim$ ARIMA(2, 1, 3) y su coeficiente $\beta_1 = 2.8$.
-   $X_t^{(2)} \sim$ ARIMA(1, 1, 2) y su coeficiente $\beta_2 = -1.12$.
-   $X_t^{(3)} \sim$ ARMA(1, 2) y su coeficiente $\beta_3 = -2.3$.
-   El *intercept* es $\beta_0=0.8$.

Supongamos otro conjunto de variables (que siguen también un proceso ARIMA) que no van a influir en la variable respuesta:

-   $X_t^{(4)} \sim$ ARIMA(1, 0, 3).
-   $X_t^{(5)} \sim$ ARIMA(2, 1, 2).
-   $X_t^{(6)} \sim$ ARIMA(2, 1, 1).

```{r}
# Cargamos los datos sobre las variables regresoras
load(file='simulations/X1 ~ ARIMA(2,1,3).RData')        # X1
load(file='simulations/X2 ~ ARIMA(1,1,2).RData')        # X2
load(file='simulations/X3 ~ ARIMA(1,0,2).RData')        # X3
load(file='simulations/residuals ~ ARIMA(2,0,1).RData') # residuals

# Cargamos las variables independientes
load(file='simulations/X4 ~ ARIMA(1,0,3).RData')        # X4
load(file='simulations/X5 ~ ARIMA(2,1,2).RData')        # X5
load(file='simulations/X6 ~ ARIMA(2,1,1).RData')        # X6
```

Se puede realizar una comprobación de que estas series siguen los procesos ARIMA mencionados. Para chequearlo, consulte el [apéndice](#apendice) del documento.

Creamos el modelo y comprobamos la solución final de la función `auto.fit.arima.regression`.

```{r}
beta0 <- 0.8; beta1 <- 2.8; beta2 <- -1.12; beta3 <- -2.3
Y <- beta0 + beta1 * X1$X + beta2 * X2$X + beta3 * X3$X + residuals$X
regresoras <- cbind(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T)
```


Finalmente realizamos las predicciones puntuales:

```{r}
preds <- forecast_model(Y, regresoras, ajuste, h=10, mode='bootstrap')
display(plot_forecast(preds, rang=c(950, 1009)), name='ejemplo1')
```


## Modelo donde $r_i\geq 0$ para $i=1,...,p$ {#ejemplo2}

Supongamos un modelo de regresión dinámica parecido al del [primer ejemplo](#ejemplo1), utilizando las mismas variables, pero donde los retardos sean menores o iguales a 0 (que haya "variedad" en los retardos).

$$ Y_t = \beta_0 + \beta_1 X_{t-r_1}^{(1)} + \beta_2 X_{t-r_2}^{(2)} + \beta_3 X_{t-r_3}^{(3)} + \eta_t$$

donde:

-   $\eta_t \sim$ ARMA(2, 1).
-   $X_t^{(1)} \sim$ ARIMA(2, 1, 3) y su retardo $r_1=2$.
-   $X_t^{(2)} \sim$ ARMA(1, 1, 2) y su retardo $r_2=0$.
-   $X_t^{(3)} \sim$ ARMA(1, 0, 2) y su retardo $r_3=3$.

```{r}
# Construimos el modelo 
beta0 <- -0.6; beta1 <- 1.7; beta2 <- -2.2; beta3 <- 1.3
r1 <- 2; r3 <- 3
Y <- beta0 + beta1 * lag(X1$X, -r1) + beta2 * X2$X + beta3 * lag(X3$X, -r3) + 
    residuals$X

# Usamos la función
regresoras <- cbind(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T,  
                                    stationary_method='adf.test')

```

```{r}
# Podemos mostrar las predicciones puntuales
preds <- forecast_model(Y, regresoras, ajuste, h=10, mode='bootstrap')
display(plot_forecast(preds, rang=c(950, 1009)), name='ejemplo2')
```




# Simulación de un modelo de regresión dinámico con errores ARIMA ($d=1$)

En esta sección consideraremos modelos de regresión dinámica donde las innovaciones no son estacionarias:

$$Y_t = \beta_0 + \beta_1 X_{t-r_1}^{(1)} + \beta_2 X_{t-r_2}^{(2)} + \cdots + X_{t-r_p}^{(p)}+ \eta_t, \qquad \eta_t\sim \text{ARIMA(p,d,q)} $$


## Modelo donde $r_i=0$ para $i=1,...,p$

Tomemos el mismo modelo que en el [primer ejemplo](#ejemplo1) pero con errores no estacionarios:

$$ Y_t = \beta_0 + \beta_1 X_t^{(1)} + \beta_2 X_t^{(2)} + \beta_3 X_t^{(3)} + \eta_t, \qquad \eta_t\sim\text{ARIMA(1,2,2)}$$

donde el conjunto de variables $\mathcal{X}$ sobre el que se realiza la selección está compuesto por las variables que sí influyen en $Y$:

-   $X_t^{(1)} \sim$ ARIMA(2, 1, 3) y su coeficiente $\beta_1 = 2.8$.
-   $X_t^{(2)} \sim$ ARIMA(1, 1, 2) y su coeficiente $\beta_2 = 2.12$.
-   $X_t^{(3)} \sim$ ARMA(1, 2) y su coeficiente $\beta_3 = 2.3$.
-   El *intercept* es $\beta_0=0.8$.

Y las variables que no interfieren en $Y$ (las mismas que en el [primer ejemplo](#ejemplo1)).

```{r}
# cargamos únicamente los residuos no estacionarios
load('simulations/residuals ~ ARIMA(1,2,2).RData')

# volvemos a generar la variable respuesta 
beta0 <- 0.8; beta1 <- -1.3; beta2 <- 2.12; beta3 <- 2.3
Y <- beta0 + beta1 * X1$X + beta2 * X2$X + beta3 * X3$X + 2.1*residuals$X
```

Ajustamos el modelo con las variables originales (no diferenciamos ninguna):

```{r}
regresoras <- cbind(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T) 
```

```{r}
preds <- forecast_model(Y, regresoras, ajuste, h=10, mode='bootstrap')
display(plot_forecast(preds, rang=c(950, 1009)), name='ejemplo3')
```



## Modelo donde $r_i \geq 0$ para $i=1,...,p$

Podemos alterar el ejemplo anterior para que las variables regresoras influyan en $Y$ con cierto retardo. 

- La variable $X_t^{(1)}$ se introduce con retardo $r_1=2$.
- La variable $X_t^{(3)}$ se introduce con retardo $r_3=1$.


```{r}
# Creación del modelo con los nuevos residuos
beta0 <- 0.8; beta1 <- -1.3; beta2 <- 2.12; beta3 <- 2.3
r1 <- 2; r3 <- 1
Y <- beta0 + beta1 * lag(X1$X, -r1) + beta2 * X2$X + 
    beta3 * lag(X3$X, -r3) + 1.5*residuals$X

regresoras <- cbind(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
auto.fit.arima.regression(Y, regresoras, show_info=T, 
                          stationary_method='adf.test')
```

\newpage

# Comparativa del método de preblanqueado

## Con errores estacionarios

```{r}
load(file='simulations/residuals ~ ARIMA(2,0,1).RData') # residuals
beta0 <- -0.1; beta1 <- 3.2; beta2 <- -2.5
r1 <- 2; r2 <- 3
Y <- beta0 + beta1 * lag(X1$X, -r1) + beta2 * lag(X2$X, -r2) + residuals$X
regresoras <- cbind(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
```

Ajustamos un modelo usando como método para chequear estacionariedad la función `auto.arima`:

```{r}
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T, 
                                    stationary_method='auto.arima')
```

Ajustamos un modelo usando como método para chequear estacionariedad el `adf.test`:

```{r}
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T,
                                    stationary_method='adf.test')
```

## Con errores no estacionarios

```{r}
load(file='simulations/residuals ~ ARIMA(1,2,2).RData') # residuals
beta0 <- -0.1; beta1 <- 3.2; beta2 <- -2.5
r1 <- 2; r2 <- 3
Y <- beta0 + beta1 * lag(X1$X, -r1) + beta2 * lag(X2$X, -r2) + residuals$X
regresoras <- cbind(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
```

Ajustamos un modelo usando como método para chequear estacionariedad la función `auto.arima`:

```{r}
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T, 
                                    stationary_method='auto.arima')
```

Ajustamos un modelo usando como método para chequear estacionariedad el `adf.test`:

```{r}
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T,
                                    stationary_method='adf.test')
```


\newpage

# Apéndice {#apendice}

En esta sección se muestra la comprobación con la función `auto.fit.arima` de que las muestras cargadas cumplen con los requisitos mencionados.

Para el [primer ejempo](#ejemplo1), las muestras simuladas eran las siguientes:

```{r}
load(file='simulations/residuals ~ ARIMA(2,0,1).RData') # residuals
```

Si la función `auto.fit.arima` y observamos los *outputs*, vemos que siguen el proceso ARIMA anotado:

```{r}
auto.fit.arima(X1$X, show_info=F)
auto.fit.arima(X2$X, show_info=F)
auto.fit.arima(X3$X, show_info=F)
auto.fit.arima(residuals$X, show_info=F)
auto.fit.arima(X4$X, show_info=F)
auto.fit.arima(X5$X, show_info=F)
auto.fit.arima(X6$X, show_info=F)
```

Podemos hacer la misma comprobación con los residuos del [ejemplo 2](#ejemplo2).

```{r}
load('simulations/residuals ~ ARIMA(1,2,2).RData')
auto.fit.arima(residuals$X, show_info=F)
```

