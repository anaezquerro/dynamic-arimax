---
title: "Simulación"
author: "Ana Xiangning Pereira Ezquerro"
date:  "Versión `r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::pdf_document2:
    number_sections: yes
    latex_engine: lualatex
    fig_caption: yes
    toc: yes
    highlight: tango
    df_print: kable
    citation_package: biblatex
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    number_sections: true
    theme: hpstr
    highlight: tango
  prettydoc::html_pretty:
    toc: true
    df_print: paged
    number_sections: true
    theme: hpstr
    highlight: github
fontsize: 12pt
geometry: margin=0.7in
classoption: a4paper
documentclass: article
header-includes:
- \usepackage{sfmath}
- \usepackage{csquotes}
- \renewcommand*\familydefault{\sfdefault}
- \renewcommand{\baselinestretch}{1.2}
- \setlength{\parskip}{1em}
- \input{confi.tex}
always_allow_html: yes
bibliography: references.bib
biblio-style: bwl-FU
linkcitations: true
linkcolor: blue
lang: es
---


```{r, echo=F, warning=F, message=F}
knitr::opts_chunk$set(fig.align='center', fig.width = 10, 
                      fig.height = 8, message=F, warning = F,
                      comment='')
eval(parse("arima_simulation.R", encoding="UTF-8"))
eval(parse("auto_fit_arima.R", encoding="UTF-8"))
eval(parse("automatic_selection.R", encoding="UTF-8"))
eval(parse("forecasting.R", encoding="UTF-8"))

library(fpp2)
library(tseries)
library(TSA)
library(latex2exp)
library(plotly)
library(seastests)
library(prettydoc)
library(stringi)
library(stringr)
library(polynom)
library(forecast)

dir.create(file.path('figures'), showWarnings = FALSE)

# Función para mostrar y guardar las gráficas de plotly
display <- function(fig, name, width=800, height=400) {
  
  if (is.null(knitr::opts_knit$get("rmarkdown.pandoc.to"))) {
    return(fig)
  }
  if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "latex") {
    figpath <- paste0('figures/', name, ".pdf")
    save_image(fig, figpath, width=width, height=height)
    return(knitr::include_graphics(figpath))
  }
  if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "html") {
    return(fig)
  }
}
```

\vspace{3em}

En este documento se exponen múltiples simulaciones de la selección automática de variables con sus respectivos retardos usando una nueva propuesta. Se mostrarán ejemplos donde la selección automática trabaja sobre un conjunto de variables de las cuales sólo algunas inciden en la variable respuesta y con un retardo concreto (aunque siempre menor o igual a 0). A lo largo de las siguientes secciones se irán complicando escenarios con al finalidad de analizar cómo se comporta la nueva propuesta ante datos simulados e inferir a partir de ellos cómo se comportará en escenarios reales.

**Nota**: Para generar los datos de las simulaciones se usó del código `arima_simulation.R`, el cual permite generar de forma pseudo-aleatoria series temporales a partir de un proceso ARIMA. Este documento no muestra cómo generar las series (para evitar la aleatoriedad de los resultados), sino que, una vez generadas y guardadas, se cargan directamente de memoria.

\newpage

# Simulación de un modelo de regresión dinámica con innovaciones estacionarias

En esta sección veremos cómo se comporta la función de selección automática sobre ejemplos muy básicos donde las innovaciones del modelo son estacionarias:

\[Y_t = \beta_0 + \beta_1 X_{t-r_1}^{(1)} + \beta_2 X_{t-r_2}^{(2)} + \cdots + X_{t-r_p}^{(p)}+ \eta_t \]

donde $\eta_t \sim$ ARMA(p,q) (equivalentemente, un ARIMA donde $d=0$).

## Modelo donde $r_i=0$ para $i=1,...,p$ {#ejemplo1}

Supongamos un modelo de regresión dinámica de tres variables regresoras donde todos los retardos son igual a cero ($r_i=0, \forall i\in[1, p]$). En concreto, nuestro modelo tendrá la forma:

\[ Y_t = \beta_0 + \beta_1 X_t^{(1)} + \beta_2 X_t^{(2)} + \beta_3 X_t^{(3)} + \eta_t\]

donde:

* $\eta_t \sim$ ARMA(2, 1), es decir, las innovaciones son estacionarias.
* $X_t^{(1)} \sim$ ARIMA(2, 1, 3) y su coeficiente $\beta_1 = 2.8$.
* $X_t^{(2)} \sim$ ARMA(1, 1, 2) y su coeficiente $\beta_2 = -1.12$.
* $X_t^{(3)} \sim$ ARMA(1, 0, 2) y su coeficiente $\beta_3 = -2.3$.
* El *intercept* es $\beta_0=0.8$.

Supongamos otro conjunto de variables (que siguen también un proceso ARIMA) que no van a influir 
en la variable respuesta:

* $X_t^{(4)} \sim$ ARIMA(1, 1, 3).
* $X_t^{(5)} \sim$ ARIMA(0, 0, 2).
* $X_t^{(6)} \sim$ ARIMA(2, 1, 1).

```{r}
# Cargamos los datos sobre las variables regresoras
load(file='simulaciones/X1 ~ ARIMA(2,1,3).RData')        # X1
load(file='simulaciones/X2 ~ ARIMA(1,1,2).RData')        # X2
load(file='simulaciones/X3 ~ ARIMA(1,0,2).RData')        # X3
load(file='simulaciones/residuals ~ ARIMA(2,0,1).RData') # residuals

# Cargamos las variables independientes
load(file='simulaciones/X4 ~ ARIMA(1,1,3).RData')        # X4
load(file='simulaciones/X5 ~ ARIMA(0,0,2).RData')        # X5
load(file='simulaciones/X6 ~ ARIMA(2,1,1).RData')        # X6
```

Se puede realizar una comprobación de que estas series siguen los procesos ARIMA mencionados. Para chequearlo, consulte el [apéndice](#apendice) del documento.


Creamos el modelo y comprobamos la solución final de la función `auto.fit.arima.regression`.
```{r}
beta0 <- 0.8; beta1 <- 2.8; beta2 <- -1.12; beta3 <- -2.3
Y <- beta0 + beta1 * X1$X + beta2 * X2$X + beta3 * X3$X + residuals$X
regresoras <- data.frame(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T)
```

Finalmente realizamos las predicciones puntuales:

```{r}
preds <- forecast_model(ajuste, h=10, mode='bootstrap', levels=c(70, 80, 90))
display(plot_forecast(preds), name='ejemplo1')
```



## Modelo donde $r_i\leq 0$ para $i=1,...,p$ {#ejemplo2}

Supongamos un modelo de regresión dinámica parecido al del [primer ejemplo](#ejemplo1), pero donde los retardos sean menores o iguales a 0 (que haya "variedad" en los retardos).

\[ Y_t = \beta_0 + \beta_1 X_{t-r_1}^{(1)} + \beta_2 X_{t-r_2}^{(2)} + \beta_3 X_{t-r_3}^{(3)} + \eta_t\]

donde:

* $\eta_t \sim$ ARMA(2, 1).
* $X_t^{(1)} \sim$ ARIMA(2, 1, 3)  y su retardo $r_1=-2$.
* $X_t^{(2)} \sim$ ARMA(1, 1, 2) y su retardo $r_2=0$. 
* $X_t^{(3)} \sim$ ARMA(1, 0, 2) y su retardo $r_3=-3$.

```{r}
# Construimos el modelo 
beta0 <- -0.1; beta1 <- 1.2; beta2 <- -4.2; beta3 <- 3.3
r1 <- -2; r3 <- -3
Y <- beta0 + beta1 * lag(X1$X, r1) + beta2 * X2$X + beta3 * lag(X3$X, r3) + 
    residuals$X

# Usamos la función
regresoras <- data.frame(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
regresoras <- as.data.frame(
    lapply(regresoras, window, start=start(Y)[1], end=end(Y)[1])
)
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T,  
                                    stationary_method='adf.test')
```


# Simulación de un modelo de regresión dinámico con errores ARIMA ($d=1$)

En esta sección consideraremos modelos de regresión dinámica donde las innovaciones no son estacionarias:


\[Y_t = \beta_0 + \beta_1 X_{t-r_1}^{(1)} + \beta_2 X_{t-r_2}^{(2)} + \cdots + X_{t-r_p}^{(p)}+ \eta_t \]

donde $\eta_t \sim$ ARIMA(p,d,q).


## Modelo donde $r_i=0$ para $i=1,...,p$


Tomemos el mismo modelo que en el [primer ejemplo](#ejemplo1) pero con innovaciones no estacionarias:

\[ Y_t = \beta_0 + \beta_1 X_t^{(1)} + \beta_2 X_t^{(2)} + \beta_3 X_t^{(3)} + \eta_t\]

donde:

* $\eta_t \sim$ ARMA(1, 2, 2), es decir, las innovaciones son estacionarias.
* $X_t^{(1)} \sim$ ARIMA(2, 1, 3) y su coeficiente $\beta_1 = 2.8$.
* $X_t^{(2)} \sim$ ARMA(1, 1, 2) y su coeficiente $\beta_2 = -1.12$.
* $X_t^{(3)} \sim$ ARMA(2, 2, 3) y su coeficiente $\beta_3 = -2.3$.
* El *intercept* es $\beta_0=0.8$.


```{r}
load(file='simulaciones/X1 ~ ARIMA(2,1,3).RData')
load(file='simulaciones/X2 ~ ARIMA(1,2,1).RData')
load(file='simulaciones/X3 ~ ARIMA(2,2,3).RData')
load(file='simulaciones/X4 ~ ARIMA(1,1,3).RData')
load(file='simulaciones/X5 ~ ARIMA(0,1,2).RData')
load(file='simulaciones/X6 ~ ARIMA(2,1,1).RData')
load('simulaciones/residuals ~ ARIMA(1, 2, 2).RData')
beta0 <- 0.8; beta1 <- -1.3; beta2 <- 7.12; beta3 <- 12.3
Y <- beta0 + beta1 * X1$X + beta2 * X2$X + beta3 * X3$X + 2.1*residuals$X
```


Ajustamos el modelo con las variables originales (no diferenciamos ninguna):

```{r}
regresoras <- data.frame(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
auto.fit.arima.regression(Y, regresoras, show_info=T) 
```


Podemos observar cómo la función ha realizado una diferenciación regular a todas las series (respusta y regresoras). El resultado final es que las variables $X^{(1)}$ y $X^{(2)}$ intervienen en la variable respuesta, y que los residuos son un ARIMA(2, 0, 0). Obsérvese que los órdenes de los residuos son muy distintos a los que se han usado para generarlos. Etso se debe a las diferenciaciones regulares que se le ha aplicado a todo el conjunto de datos. 


## Modelo con retardos $r<0$


```{r}
# Creación del modelo con los nuevos residuos
beta0 <- 0.8; beta1 <- 6.8; beta2 <- 1.12; beta3 <- 12.3
r1 <- -2; r3 <- -1
Y <- beta0 + beta1 * lag(X1$X, r1) + beta2 * X2$X + 
    beta3 * lag(X3$X, r3) + 1.5*residuals$X

regresoras <- data.frame(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
auto.fit.arima.regression(Y, regresoras, show_info=T, 
                          stationary_method='adf.test')
```


\newpage

# Comparativa del método de preblanqueado

## Preblanqueado en base al `adf.test`

Creamos variables regresoras con órdenes $d$ distintos y retardos distintos:

```{r}
# Variables que influyen en el modelo
load(file='simulaciones/X1 ~ ARIMA(2,1,3).RData')
load(file='simulaciones/X2 ~ ARIMA(1,2,1).RData')
load(file='simulaciones/X3 ~ ARIMA(2,2,3).RData')
load(file='simulaciones/X4 ~ ARIMA(1,1,3).RData')
load(file='simulaciones/X5 ~ ARIMA(0,1,2).RData')
load(file='simulaciones/X6 ~ ARIMA(2,1,1).RData')
load(file='simulaciones/residuals ~ ARIMA(2,0,1).RData')
```


```{r}
beta0 <- -0.1; beta1 <- 8.2; beta2 <- -0.5
r1 <- -2; r2 <- -3
Y <- beta0 + beta1 * lag(X1$X, r1) + beta2 * lag(X2$X, r2) + residuals$X
```

Ajustamos un modelo usando como método para chequear estacionariedad la función `auto.arima`:
```{r}
regresoras <- data.frame(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
regresoras <- as.data.frame(lapply(regresoras, window, 
                                   start=start(Y)[1], end=end(Y)[1]))
auto.fit.arima.regression(Y, regresoras, show_info=T, 
                          stationary_method='auto.arima')
```

Ajustamos un modelo usando como método para chequear estacionariedad el `adf.test`:

```{r}
regresoras <- data.frame(X1=X1$X, X2=X2$X, X3=X3$X, X4=X4$X, X5=X5$X, X6=X6$X)
regresoras <- as.data.frame(lapply(regresoras, window, 
                                   start=start(Y)[1], end=end(Y)[1]))
ajuste <- auto.fit.arima.regression(Y, regresoras, show_info=T,
                                    stationary_method='adf.test')
```




# Apéndice {#apendice}

En esta sección se muestra la comprobación con la función `auto.fit.arima` de que las muestras cargadas cumplen con los requisitos mencionados.

Para el [primer ejempo](#ejemplo1), las muestras simuladas eran las siguientes:

```{r}
load(file='simulaciones/X1 ~ ARIMA(2,1,3).RData')        # X1
load(file='simulaciones/X2 ~ ARIMA(1,1,2).RData')        # X2
load(file='simulaciones/X3 ~ ARIMA(1,0,2).RData')        # X3
load(file='simulaciones/residuals ~ ARIMA(2,0,1).RData') # residuals
load(file='simulaciones/X4 ~ ARIMA(1,1,3).RData')        # X4
load(file='simulaciones/X5 ~ ARIMA(0,0,2).RData')        # X5
load(file='simulaciones/X6 ~ ARIMA(2,1,1).RData')        # X6
```

Si la función `auto.fit.arima` y observamos los *outputs*, vemos que siguen el proceso ARIMA anotado:

```{r}
auto.fit.arima(X1$X, show_info=F)
auto.fit.arima(X2$X, show_info=F)
auto.fit.arima(X3$X, show_info=F)
auto.fit.arima(residuals$X, show_info=F)
auto.fit.arima(X4$X, show_info=F)
auto.fit.arima(X5$X, show_info=F)
auto.fit.arima(X6$X, show_info=F)
```

Podemos hacer la misma comprobación con las series del [ejemplo 2](#ejemplo2)

